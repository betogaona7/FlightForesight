{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75e375f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, make_scorer, recall_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115460b3",
   "metadata": {},
   "source": [
    "## Load data \n",
    "\n",
    "SCL_flights_full contains the columns from SCL_flights_data_extra and SCL_flights_data(original), so it is the one useful to create a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a255c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (68206, 22)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 68206 entries, 13375 to 10196\n",
      "Data columns (total 22 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Fecha-I         68206 non-null  object \n",
      " 1   Vlo-I           68206 non-null  object \n",
      " 2   Ori-I           68206 non-null  object \n",
      " 3   Des-I           68206 non-null  object \n",
      " 4   Emp-I           68206 non-null  object \n",
      " 5   Fecha-O         68206 non-null  object \n",
      " 6   Vlo-O           68205 non-null  object \n",
      " 7   Ori-O           68206 non-null  object \n",
      " 8   Des-O           68206 non-null  object \n",
      " 9   Emp-O           68206 non-null  object \n",
      " 10  DIA             68206 non-null  int64  \n",
      " 11  MES             68206 non-null  int64  \n",
      " 12  AÑO             68206 non-null  int64  \n",
      " 13  DIANOM          68206 non-null  object \n",
      " 14  TIPOVUELO       68206 non-null  object \n",
      " 15  OPERA           68206 non-null  object \n",
      " 16  SIGLAORI        68206 non-null  object \n",
      " 17  SIGLADES        68206 non-null  object \n",
      " 18  temporada_alta  68206 non-null  int64  \n",
      " 19  dif_min         68206 non-null  float64\n",
      " 20  atraso_15       68206 non-null  int64  \n",
      " 21  periodo_dia     66976 non-null  object \n",
      "dtypes: float64(1), int64(5), object(16)\n",
      "memory usage: 12.0+ MB\n",
      "Info: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57654/1844148116.py:1: DtypeWarning: Columns (1,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./../datasets/SCL_flights_full.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./../datasets/SCL_flights_full.csv')\n",
    "\n",
    "# shuffle data with the same random_state as to-expose.ipynb for an approx comparission\n",
    "df = shuffle(df, random_state=111)\n",
    "\n",
    "print(f\"data shape: {df.shape}\")\n",
    "print(f\"Info: {df.info()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e37504",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "The features to use, based on the assumption that they may influece on whether a flight gets delayed or not, are: \n",
    "- **DIA** (numerical) - Airport can be busy\n",
    "- **MES** (numerical) - Seasons factors\n",
    "- **temporada_alta** (numerical) - High congestion at the airport\n",
    "- **DIANOM** Nombre del día (categorical) - Day of the week\n",
    "- **TIPOVUELO** vuelo nacional o internacional (categorical) - different procedures\n",
    "- **OPERA** Nombre de la aerolinea (categorical) - different operational procedures\n",
    "- **SIGLAORI** Ciudad de origen (categorical) - airport status\n",
    "- **SIGLADES** Ciudad de destino (categorical) - airport status \n",
    "- **periodo_dia** (categorical) - some periods can be busier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3065c814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dist: \n",
      "1    0.501764\n",
      "0    0.498236\n",
      "Name: atraso_15, dtype: float64\n",
      "Testing dist: \n",
      "0    0.503581\n",
      "1    0.496419\n",
      "Name: atraso_15, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create one-hot encoded vectors\n",
    "features = pd.get_dummies(df, columns=['DIANOM', 'TIPOVUELO', 'OPERA', 'SIGLAORI', 'SIGLADES', 'periodo_dia'])\n",
    "\n",
    "# Drop irrelevant columns\n",
    "features.drop(['Fecha-I', \n",
    "         'Fecha-O', \n",
    "         'Vlo-I', \n",
    "         'Vlo-O', \n",
    "         'AÑO', \n",
    "         'dif_min', \n",
    "         'Ori-O', \n",
    "         'Des-O', \n",
    "         'Emp-O', \n",
    "         'Ori-I', \n",
    "         'Des-I', \n",
    "         'Emp-I'], axis=1, inplace=True)\n",
    "\n",
    "# Keep 20% of data for testing\n",
    "training_set, testing_set = train_test_split(features, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define input and expected output data\n",
    "X = training_set.drop('atraso_15', axis=1)\n",
    "y = training_set['atraso_15']\n",
    "\n",
    "# Fix class imbalance, these new samples are generated by interpolating between the existing \n",
    "# samples in the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Create training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.33, random_state=42)\n",
    "\n",
    "print(f\"Training dist: \\n{y_train.value_counts('%')}\")\n",
    "print(f\"Testing dist: \\n{y_val.value_counts('%')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5bd43e",
   "metadata": {},
   "source": [
    "## Create model\n",
    "\n",
    "The models in to-expose.ipynb were not using enough features to predict a flight delay, besides that, they had very poor performance since the recall for class 1 (delayed flights) was at only 0.03 which indicates that the model is not good identifying delays (it correctly identified only 3% of them). This is due to unbalanced data. \n",
    "\n",
    "So, in this new model, both of those problems were addressed in the above cell, more features and balanced data. This significantly improved the model and increased the class 1 recall to around 20%.\n",
    "\n",
    "To improve it more, a grid search was done in the following cell using the Recall score as metric; This because it is better to say that a flight is going to be delayed and be wrong than saying that a flight is going to be on-time and be wrong..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(eval_metric='logloss', random_state=1)\n",
    "\n",
    "# Define the hyperparameters\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "# Use recall score as the evaluation metric for GridSearchCV\n",
    "recall_scorer = make_scorer(recall_score, greater_is_better=True)\n",
    "\n",
    "# Dearch \n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=recall_scorer, cv=3, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best combination of hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f76f1f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 200, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e69c0050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.73      0.78     14764\n",
      "           1       0.76      0.86      0.80     14554\n",
      "\n",
      "    accuracy                           0.79     29318\n",
      "   macro avg       0.80      0.79      0.79     29318\n",
      "weighted avg       0.80      0.79      0.79     29318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 200, 'subsample': 1.0}\n",
    "model = xgb.XGBClassifier(eval_metric='logloss', random_state=1, **best_params)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ac84d",
   "metadata": {},
   "source": [
    "## Test model \n",
    "\n",
    "Validate the results with real data (without generated samples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a2c1bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.72      0.79     11171\n",
      "           1       0.30      0.54      0.38      2471\n",
      "\n",
      "    accuracy                           0.69     13642\n",
      "   macro avg       0.59      0.63      0.59     13642\n",
      "weighted avg       0.77      0.69      0.72     13642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define input and expected output data\n",
    "X = testing_set.drop('atraso_15', axis=1)\n",
    "y = testing_set['atraso_15']\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25680ae7",
   "metadata": {},
   "source": [
    "Observe that the recall for class 1 (delayed flights), altough is relatively low, it is an improvement compared to the previous models (to_expose.ipynb). It also indicates that there is still room for improvements, feature engineering might help. For example, SIGLAORI may not be needed since in all the dataset, it has always the value of \"Santiago\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b38655b",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69e4e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('mynewmodel.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee81f0d",
   "metadata": {},
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d721106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIA\n",
      "MES\n",
      "temporada_alta\n",
      "DIANOM_Domingo\n",
      "DIANOM_Jueves\n",
      "DIANOM_Lunes\n",
      "DIANOM_Martes\n",
      "DIANOM_Miercoles\n",
      "DIANOM_Sabado\n",
      "DIANOM_Viernes\n",
      "TIPOVUELO_I\n",
      "TIPOVUELO_N\n",
      "OPERA_Aerolineas Argentinas\n",
      "OPERA_Aeromexico\n",
      "OPERA_Air Canada\n",
      "OPERA_Air France\n",
      "OPERA_Alitalia\n",
      "OPERA_American Airlines\n",
      "OPERA_Austral\n",
      "OPERA_Avianca\n",
      "OPERA_British Airways\n",
      "OPERA_Copa Air\n",
      "OPERA_Delta Air\n",
      "OPERA_Gol Trans\n",
      "OPERA_Grupo LATAM\n",
      "OPERA_Iberia\n",
      "OPERA_JetSmart SPA\n",
      "OPERA_K.L.M.\n",
      "OPERA_Lacsa\n",
      "OPERA_Latin American Wings\n",
      "OPERA_Oceanair Linhas Aereas\n",
      "OPERA_Plus Ultra Lineas Aereas\n",
      "OPERA_Qantas Airways\n",
      "OPERA_Sky Airline\n",
      "OPERA_United Airlines\n",
      "SIGLAORI_Santiago\n",
      "SIGLADES_Antofagasta\n",
      "SIGLADES_Arica\n",
      "SIGLADES_Asuncion\n",
      "SIGLADES_Atlanta\n",
      "SIGLADES_Auckland N.Z.\n",
      "SIGLADES_Balmaceda\n",
      "SIGLADES_Bariloche\n",
      "SIGLADES_Bogota\n",
      "SIGLADES_Buenos Aires\n",
      "SIGLADES_Calama\n",
      "SIGLADES_Cancun\n",
      "SIGLADES_Castro (Chiloe)\n",
      "SIGLADES_Cataratas Iguacu\n",
      "SIGLADES_Ciudad de Mexico\n",
      "SIGLADES_Ciudad de Panama\n",
      "SIGLADES_Cochabamba\n",
      "SIGLADES_Concepcion\n",
      "SIGLADES_Copiapo\n",
      "SIGLADES_Cordoba\n",
      "SIGLADES_Curitiba, Bra.\n",
      "SIGLADES_Dallas\n",
      "SIGLADES_Florianapolis\n",
      "SIGLADES_Guayaquil\n",
      "SIGLADES_Houston\n",
      "SIGLADES_Iquique\n",
      "SIGLADES_Isla de Pascua\n",
      "SIGLADES_La Paz\n",
      "SIGLADES_La Serena\n",
      "SIGLADES_Lima\n",
      "SIGLADES_Londres\n",
      "SIGLADES_Los Angeles\n",
      "SIGLADES_Madrid\n",
      "SIGLADES_Melbourne\n",
      "SIGLADES_Mendoza\n",
      "SIGLADES_Miami\n",
      "SIGLADES_Montevideo\n",
      "SIGLADES_Neuquen\n",
      "SIGLADES_Nueva York\n",
      "SIGLADES_Orlando\n",
      "SIGLADES_Osorno\n",
      "SIGLADES_Paris\n",
      "SIGLADES_Pisco, Peru\n",
      "SIGLADES_Puerto Montt\n",
      "SIGLADES_Puerto Natales\n",
      "SIGLADES_Puerto Stanley\n",
      "SIGLADES_Punta Arenas\n",
      "SIGLADES_Punta Cana\n",
      "SIGLADES_Punta del Este\n",
      "SIGLADES_Quito\n",
      "SIGLADES_Rio de Janeiro\n",
      "SIGLADES_Roma\n",
      "SIGLADES_Rosario\n",
      "SIGLADES_San Juan, Arg.\n",
      "SIGLADES_Santa Cruz\n",
      "SIGLADES_Sao Paulo\n",
      "SIGLADES_Sydney\n",
      "SIGLADES_Temuco\n",
      "SIGLADES_Toronto\n",
      "SIGLADES_Tucuman\n",
      "SIGLADES_Ushuia\n",
      "SIGLADES_Valdivia\n",
      "SIGLADES_Washington\n",
      "periodo_dia_mañana\n",
      "periodo_dia_noche\n",
      "periodo_dia_tarde\n"
     ]
    }
   ],
   "source": [
    "# list of values we should pass as input for inference\n",
    "for val in X.columns:\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a945c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, create a single dict header\n",
    "data_headers_dict = {\n",
    "    \"DIA\" : 0,\n",
    "    \"MES\" : 0,\n",
    "    \"temporada_alta\" : 0,\n",
    "    \"DIANOM_Domingo\" : 0,\n",
    "    \"DIANOM_Jueves\" : 0,\n",
    "    \"DIANOM_Lunes\" : 0,\n",
    "    \"DIANOM_Martes\" : 0,\n",
    "    \"DIANOM_Miercoles\" : 0,\n",
    "    \"DIANOM_Sabado\" : 0,\n",
    "    \"DIANOM_Viernes\" : 0,\n",
    "    \"TIPOVUELO_I\" : 0,\n",
    "    \"TIPOVUELO_N\" : 0,\n",
    "    \"OPERA_Aerolineas Argentinas\" : 0,\n",
    "    \"OPERA_Aeromexico\" : 0,\n",
    "    \"OPERA_Air Canada\" : 0,\n",
    "    \"OPERA_Air France\" : 0,\n",
    "    \"OPERA_Alitalia\" : 0,\n",
    "    \"OPERA_American Airlines\" : 0,\n",
    "    \"OPERA_Austral\" : 0,\n",
    "    \"OPERA_Avianca\" : 0,\n",
    "    \"OPERA_British Airways\" : 0,\n",
    "    \"OPERA_Copa Air\" : 0,\n",
    "    \"OPERA_Delta Air\" : 0,\n",
    "    \"OPERA_Gol Trans\" : 0,\n",
    "    \"OPERA_Grupo LATAM\" : 0,\n",
    "    \"OPERA_Iberia\" : 0,\n",
    "    \"OPERA_JetSmart SPA\" : 0,\n",
    "    \"OPERA_K.L.M.\" : 0,\n",
    "    \"OPERA_Lacsa\" : 0,\n",
    "    \"OPERA_Latin American Wings\" : 0,\n",
    "    \"OPERA_Oceanair Linhas Aereas\" : 0,\n",
    "    \"OPERA_Plus Ultra Lineas Aereas\" : 0,\n",
    "    \"OPERA_Qantas Airways\" : 0,\n",
    "    \"OPERA_Sky Airline\" : 0,\n",
    "    \"OPERA_United Airlines\" : 0,\n",
    "    \"SIGLAORI_Santiago\" : 0,\n",
    "    \"SIGLADES_Antofagasta\" : 0,\n",
    "    \"SIGLADES_Arica\" : 0,\n",
    "    \"SIGLADES_Asuncion\" : 0,\n",
    "    \"SIGLADES_Atlanta\" : 0,\n",
    "    \"SIGLADES_Auckland N.Z.\" : 0,\n",
    "    \"SIGLADES_Balmaceda\" : 0,\n",
    "    \"SIGLADES_Bariloche\" : 0,\n",
    "    \"SIGLADES_Bogota\" : 0,\n",
    "    \"SIGLADES_Buenos Aires\" : 0,\n",
    "    \"SIGLADES_Calama\" : 0,\n",
    "    \"SIGLADES_Cancun\" : 0,\n",
    "    \"SIGLADES_Castro (Chiloe)\" : 0,\n",
    "    \"SIGLADES_Cataratas Iguacu\" : 0,\n",
    "    \"SIGLADES_Ciudad de Mexico\" : 0,\n",
    "    \"SIGLADES_Ciudad de Panama\" : 0,\n",
    "    \"SIGLADES_Cochabamba\" : 0,\n",
    "    \"SIGLADES_Concepcion\" : 0,\n",
    "    \"SIGLADES_Copiapo\" : 0,\n",
    "    \"SIGLADES_Cordoba\" : 0,\n",
    "    \"SIGLADES_Curitiba, Bra.\" : 0,\n",
    "    \"SIGLADES_Dallas\" : 0,\n",
    "    \"SIGLADES_Florianapolis\" : 0,\n",
    "    \"SIGLADES_Guayaquil\" : 0,\n",
    "    \"SIGLADES_Houston\" : 0,\n",
    "    \"SIGLADES_Iquique\" : 0,\n",
    "    \"SIGLADES_Isla de Pascua\" : 0,\n",
    "    \"SIGLADES_La Paz\" : 0,\n",
    "    \"SIGLADES_La Serena\" : 0,\n",
    "    \"SIGLADES_Lima\" : 0,\n",
    "    \"SIGLADES_Londres\" : 0,\n",
    "    \"SIGLADES_Los Angeles\" : 0,\n",
    "    \"SIGLADES_Madrid\" : 0,\n",
    "    \"SIGLADES_Melbourne\" : 0,\n",
    "    \"SIGLADES_Mendoza\" : 0,\n",
    "    \"SIGLADES_Miami\" : 0,\n",
    "    \"SIGLADES_Montevideo\" : 0,\n",
    "    \"SIGLADES_Neuquen\" : 0,\n",
    "    \"SIGLADES_Nueva York\" : 0,\n",
    "    \"SIGLADES_Orlando\" : 0,\n",
    "    \"SIGLADES_Osorno\" : 0,\n",
    "    \"SIGLADES_Paris\" : 0,\n",
    "    \"SIGLADES_Pisco, Peru\" : 0,\n",
    "    \"SIGLADES_Puerto Montt\" : 0,\n",
    "    \"SIGLADES_Puerto Natales\" : 0,\n",
    "    \"SIGLADES_Puerto Stanley\" : 0,\n",
    "    \"SIGLADES_Punta Arenas\" : 0,\n",
    "    \"SIGLADES_Punta Cana\" : 0,\n",
    "    \"SIGLADES_Punta del Este\" : 0,\n",
    "    \"SIGLADES_Quito\" : 0,\n",
    "    \"SIGLADES_Rio de Janeiro\" : 0,\n",
    "    \"SIGLADES_Roma\" : 0,\n",
    "    \"SIGLADES_Rosario\" : 0,\n",
    "    \"SIGLADES_San Juan, Arg.\" : 0,\n",
    "    \"SIGLADES_Santa Cruz\" : 0,\n",
    "    \"SIGLADES_Sao Paulo\" : 0,\n",
    "    \"SIGLADES_Sydney\" : 0,\n",
    "    \"SIGLADES_Temuco\" : 0,\n",
    "    \"SIGLADES_Toronto\" : 0,\n",
    "    \"SIGLADES_Tucuman\" : 0,\n",
    "    \"SIGLADES_Ushuia\" : 0,\n",
    "    \"SIGLADES_Valdivia\" : 0,\n",
    "    \"SIGLADES_Washington\" : 0,\n",
    "    \"periodo_dia_mañana\" : 0,\n",
    "    \"periodo_dia_noche\" : 0,\n",
    "    \"periodo_dia_tarde\" : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8fcbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./../models/model.pkl\", 'rb') as file:\n",
    "    trained_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4f399e",
   "metadata": {},
   "source": [
    "### Test a flight on-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9af884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "# create new data one-hot vector \n",
    "new_data = data_headers_dict.copy()\n",
    "\n",
    "# update dict values\n",
    "new_data['DIA'] = 15\n",
    "new_data['MES'] = 3\n",
    "new_data['temporada_alta'] = 1\n",
    "\n",
    "cat_vars_names = [\n",
    "    \"DIANOM_\" + \"Lunes\",\n",
    "    \"TIPOVUELO_\" + \"I\",\n",
    "    \"OPERA_\" + \"Delta Air\",\n",
    "    \"SIGLAORI_\" + \"Santiago\",\n",
    "    \"SIGLADES_\" + \"Ciudad de Mexico\",\n",
    "    \"periodo_dia_\" + \"noche\"\n",
    "]\n",
    "\n",
    "for name in cat_vars_names:\n",
    "    if name in new_data:\n",
    "        new_data[name] = 1\n",
    "    else: \n",
    "        print(name)\n",
    "\n",
    "print(len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85407c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on-time\n"
     ]
    }
   ],
   "source": [
    "# covert to numpy\n",
    "x = np.array(list(new_data.values())).reshape(1, -1)\n",
    "# predict \n",
    "prediction = model.predict(x)\n",
    "pred = \"delayed\" if prediction else \"on-time\"\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bedd9f6",
   "metadata": {},
   "source": [
    "### Test a delayed flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "571f163a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "# create new data one-hot vector \n",
    "new_data = data_headers_dict.copy()\n",
    "\n",
    "# update dict values\n",
    "new_data['DIA'] = 8\n",
    "new_data['MES'] = 1\n",
    "new_data['temporada_alta'] = 1\n",
    "\n",
    "cat_vars_names = [\n",
    "    \"DIANOM_\" + \"Domingo\",\n",
    "    \"TIPOVUELO_\" + \"I\",\n",
    "    \"OPERA_\" + \"Qantas Airways\",\n",
    "    \"SIGLAORI_\" + \"Santiago\",\n",
    "    \"SIGLADES_\" + \"Sydney\",\n",
    "    \"periodo_dia_\" + \"tarde\"\n",
    "]\n",
    "\n",
    "for name in cat_vars_names:\n",
    "    if name in new_data:\n",
    "        new_data[name] = 1\n",
    "    else: \n",
    "        print(name)\n",
    "\n",
    "print(len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcd082ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delayed\n"
     ]
    }
   ],
   "source": [
    "# covert to numpy\n",
    "x = np.array(list(new_data.values())).reshape(1, -1)\n",
    "# predict \n",
    "prediction = model.predict(x)\n",
    "pred = \"delayed\" if prediction else \"on-time\"\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33a4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
